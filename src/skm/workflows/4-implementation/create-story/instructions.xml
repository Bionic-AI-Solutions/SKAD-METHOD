<workflow>
  <critical>The workflow execution engine is governed by: {project-root}/_skad/core/tasks/workflow.xml</critical>
  <critical>You MUST have already loaded and processed: {installed_path}/workflow.yaml</critical>
  <critical>Communicate all responses in {communication_language} and generate all documents in {document_output_language}</critical>

  <critical>üî• CRITICAL MISSION: You are creating the ULTIMATE story context engine that prevents LLM developer mistakes, omissions or
    disasters! üî•</critical>
  <critical>Your purpose is NOT to copy from epics - it's to create a comprehensive, optimized story file that gives the DEV agent
    EVERYTHING needed for flawless implementation</critical>
  <critical>COMMON LLM MISTAKES TO PREVENT: reinventing wheels, wrong libraries, wrong file locations, breaking regressions, ignoring UX,
    vague implementations, lying about completion, not learning from past work</critical>
  <critical>üö® EXHAUSTIVE ANALYSIS REQUIRED: You must thoroughly analyze ALL artifacts to extract critical context - do NOT be lazy or skim!
    This is the most important function in the entire development process!</critical>
  <critical>üî¨ UTILIZE SUBPROCESSES AND SUBAGENTS: Use research subagents, subprocesses or parallel processing if available to thoroughly
    analyze different artifacts simultaneously and thoroughly</critical>
  <critical>‚ùì SAVE QUESTIONS: If you think of questions or clarifications during analysis, save them for the end after the complete story is
    written</critical>
  <critical>üéØ ZERO USER INTERVENTION: Process should be fully automated except for initial epic/story selection or missing documents</critical>

  <step n="1" goal="Determine target story">
    <check if="{{story_path}} is provided by user or user provided the epic and story number such as 2-4 or 1.6 or epic 1 story 5">
      <action>Parse user-provided story path: extract epic_num, story_num, story_title from format like "1-2-user-auth"</action>
      <action>Set {{epic_num}}, {{story_num}}, {{story_key}} from user input</action>
      <action>GOTO step 2a</action>
    </check>

    <action>Check if {{sprint_status}} file exists for auto discover</action>
    <check if="sprint status file does NOT exist">
      <output>üö´ No sprint status file found and no story specified</output>
      <output>
        **Required Options:**
        1. Run `sprint-planning` to initialize sprint tracking (recommended)
        2. Provide specific epic-story number to create (e.g., "1-2-user-auth")
        3. Provide path to story documents if sprint status doesn't exist yet
      </output>
      <ask>Choose option [1], provide epic-story number, path to story docs, or [q] to quit:</ask>

      <check if="user chooses 'q'">
        <action>HALT - No work needed</action>
      </check>

      <check if="user chooses '1'">
        <output>Run sprint-planning workflow first to create sprint-status.yaml</output>
        <action>HALT - User needs to run sprint-planning</action>
      </check>

      <check if="user provides epic-story number">
        <action>Parse user input: extract epic_num, story_num, story_title</action>
        <action>Set {{epic_num}}, {{story_num}}, {{story_key}} from user input</action>
        <action>GOTO step 2a</action>
      </check>

      <check if="user provides story docs path">
        <action>Use user-provided path for story documents</action>
        <action>GOTO step 2a</action>
      </check>
    </check>

    <!-- Auto-discover from sprint status only if no user input -->
    <check if="no user input provided">
      <critical>MUST read COMPLETE {sprint_status} file from start to end to preserve order</critical>
      <action>Load the FULL file: {{sprint_status}}</action>
      <action>Read ALL lines from beginning to end - do not skip any content</action>
      <action>Parse the development_status section completely</action>

      <action>Find the FIRST story (by reading in order from top to bottom) where:
        - Key matches pattern: number-number-name (e.g., "1-2-user-auth")
        - NOT an epic key (epic-X) or retrospective (epic-X-retrospective)
        - Status value equals "backlog"
      </action>

      <check if="no backlog story found">
        <output>üìã No backlog stories found in sprint-status.yaml

          All stories are either already created, in progress, or done.

          **Options:**
          1. Run sprint-planning to refresh story tracking
          2. Load PM agent and run correct-course to add more stories
          3. Check if current sprint is complete and run retrospective
        </output>
        <action>HALT</action>
      </check>

      <action>Extract from found story key (e.g., "1-2-user-authentication"):
        - epic_num: first number before dash (e.g., "1")
        - story_num: second number after first dash (e.g., "2")
        - story_title: remainder after second dash (e.g., "user-authentication")
      </action>
      <action>Set {{story_id}} = "{{epic_num}}.{{story_num}}"</action>
      <action>Store story_key for later use (e.g., "1-2-user-authentication")</action>

      <!-- Mark epic as in-progress if this is first story -->
      <action>Check if this is the first story in epic {{epic_num}} by looking for {{epic_num}}-1-* pattern</action>
      <check if="this is first story in epic {{epic_num}}">
        <action>Load {{sprint_status}} and check epic-{{epic_num}} status</action>
        <action>If epic status is "backlog" ‚Üí update to "in-progress"</action>
        <action>If epic status is "contexted" (legacy status) ‚Üí update to "in-progress" (backward compatibility)</action>
        <action>If epic status is "in-progress" ‚Üí no change needed</action>
        <check if="epic status is 'done'">
          <output>üö´ ERROR: Cannot create story in completed epic</output>
          <output>Epic {{epic_num}} is marked as 'done'. All stories are complete.</output>
          <output>If you need to add more work, either:</output>
          <output>1. Manually change epic status back to 'in-progress' in sprint-status.yaml</output>
          <output>2. Create a new epic for additional work</output>
          <action>HALT - Cannot proceed</action>
        </check>
        <check if="epic status is not one of: backlog, contexted, in-progress, done">
          <output>üö´ ERROR: Invalid epic status '{{epic_status}}'</output>
          <output>Epic {{epic_num}} has invalid status. Expected: backlog, in-progress, or done</output>
          <output>Please fix sprint-status.yaml manually or run sprint-planning to regenerate</output>
          <action>HALT - Cannot proceed</action>
        </check>
        <output>üìä Epic {{epic_num}} status updated to in-progress</output>
      </check>

      <action>GOTO step 2a</action>
    </check>
    <action>Load the FULL file: {{sprint_status}}</action>
    <action>Read ALL lines from beginning to end - do not skip any content</action>
    <action>Parse the development_status section completely</action>

    <action>Find the FIRST story (by reading in order from top to bottom) where:
      - Key matches pattern: number-number-name (e.g., "1-2-user-auth")
      - NOT an epic key (epic-X) or retrospective (epic-X-retrospective)
      - Status value equals "backlog"
    </action>

    <check if="no backlog story found">
      <output>üìã No backlog stories found in sprint-status.yaml

        All stories are either already created, in progress, or done.

        **Options:**
        1. Run sprint-planning to refresh story tracking
        2. Load PM agent and run correct-course to add more stories
        3. Check if current sprint is complete and run retrospective
      </output>
      <action>HALT</action>
    </check>

    <action>Extract from found story key (e.g., "1-2-user-authentication"):
      - epic_num: first number before dash (e.g., "1")
      - story_num: second number after first dash (e.g., "2")
      - story_title: remainder after second dash (e.g., "user-authentication")
    </action>
    <action>Set {{story_id}} = "{{epic_num}}.{{story_num}}"</action>
    <action>Store story_key for later use (e.g., "1-2-user-authentication")</action>

    <!-- Mark epic as in-progress if this is first story -->
    <action>Check if this is the first story in epic {{epic_num}} by looking for {{epic_num}}-1-* pattern</action>
    <check if="this is first story in epic {{epic_num}}">
      <action>Load {{sprint_status}} and check epic-{{epic_num}} status</action>
      <action>If epic status is "backlog" ‚Üí update to "in-progress"</action>
      <action>If epic status is "contexted" (legacy status) ‚Üí update to "in-progress" (backward compatibility)</action>
      <action>If epic status is "in-progress" ‚Üí no change needed</action>
      <check if="epic status is 'done'">
        <output>üö´ ERROR: Cannot create story in completed epic</output>
        <output>Epic {{epic_num}} is marked as 'done'. All stories are complete.</output>
        <output>If you need to add more work, either:</output>
        <output>1. Manually change epic status back to 'in-progress' in sprint-status.yaml</output>
        <output>2. Create a new epic for additional work</output>
        <action>HALT - Cannot proceed</action>
      </check>
      <check if="epic status is not one of: backlog, contexted, in-progress, done">
        <output>üö´ ERROR: Invalid epic status '{{epic_status}}'</output>
        <output>Epic {{epic_num}} has invalid status. Expected: backlog, in-progress, or done</output>
        <output>Please fix sprint-status.yaml manually or run sprint-planning to regenerate</output>
        <action>HALT - Cannot proceed</action>
      </check>
      <output>üìä Epic {{epic_num}} status updated to in-progress</output>
    </check>

    <action>GOTO step 2a</action>
  </step>

  <step n="2" goal="Load and analyze core artifacts with parallel autonomous agents">
    <critical>üî¨ EXHAUSTIVE ARTIFACT ANALYSIS - This is where you prevent future developer fuckups!</critical>
    <critical>ü§ñ AUTONOMOUS PARALLEL EXECUTION - Spawning multiple agents simultaneously for 3-4x faster analysis!</critical>

    <!-- Load all available content through discovery protocol -->
    <invoke-protocol name="discover_inputs" />
    <note>Available content: {epics_content}, {prd_content}, {architecture_content}, {ux_content}, {project_context}</note>

    <!-- PARALLEL SUBAGENT EXECUTION - All agents work simultaneously -->
    <check if="{task_tool_available} AND {subagents.enabled}">
      <output>üöÄ Spawning parallel autonomous agents for comprehensive analysis...</output>

      <invoke-parallel>
        <!-- Agent 1: Epic Analysis -->
        <subagent id="epic-analyzer" type="explore">
          <objective>
            Analyze Epic {{epic_num}} from epics content and extract COMPLETE self-sufficient context:
            - Epic objectives and business value
            - ALL stories in this epic for cross-story context
            - Our specific story {{epic_num}}.{{story_num}} requirements, user story statement, acceptance criteria
            - Technical requirements and constraints
            - Dependencies on other stories/epics
            - Success criteria
            Embed ALL findings so story file needs NO external epic reference.
          </objective>
          <context>
            <include>{epics_content}</include>
            <epic-number>{{epic_num}}</epic-number>
            <story-number>{{story_num}}</story-number>
          </context>
          <output-var>{epic_intelligence}</output-var>
        </subagent>

        <!-- Agent 2: Architecture Analysis -->
        <subagent id="arch-analyzer" type="explore">
          <objective>
            Extract architecture requirements for story {{epic_num}}.{{story_num}}:
            - Technical stack (languages, frameworks, libraries with versions)
            - Code structure (folder organization, naming conventions, file patterns)
            - API patterns (service structure, endpoint patterns, data contracts)
            - Database schemas (tables, relationships, constraints)
            - Security requirements (authentication patterns, authorization rules)
            - Performance requirements (caching strategies, optimization patterns)
            - Testing standards (frameworks, coverage expectations, test patterns)
            - Deployment patterns (environment config, build processes)
            Embed ALL relevant architecture details in findings.
          </objective>
          <context>
            <include>{architecture_content}</include>
            <story-context>{{epic_num}}.{{story_num}}</story-context>
          </context>
          <output-var>{arch_intelligence}</output-var>
        </subagent>

        <!-- Agent 3: Previous Story Intelligence (conditional) -->
        <check if="story_num > 1">
          <subagent id="prev-story-learner" type="explore">
            <objective>
              Analyze previous story ({{epic_num}}.{{story_num - 1}}) and extract learnings:
              - Dev notes and implementation decisions
              - Review feedback and corrections needed
              - Files created/modified and their patterns
              - Testing approaches that worked/didn't work
              - Problems encountered and solutions found
              - Code patterns established
              Extract ALL insights that could impact current story.
            </objective>
            <context>
              <story-file>{{story_dir}}/{{epic_num}}-{{story_num - 1}}-*.md</story-file>
            </context>
            <output-var>{previous_intelligence}</output-var>
          </subagent>
        </check>

        <!-- Agent 4: Git Pattern Analysis (conditional) -->
        <check if="git repository detected">
          <subagent id="git-analyzer" type="bash">
            <objective>
              Analyze last 5 commits for implementation patterns:
              - Run: git log -5 --name-status
              - Run: git diff HEAD~5 --stat
              Extract patterns: files modified, code conventions, library dependencies, architecture decisions, testing approaches.
            </objective>
            <output-var>{git_intelligence}</output-var>
          </subagent>
        </check>

        <!-- Agent 5: Library/Framework Research (conditional) -->
        <check if="specific libraries/frameworks identified in architecture">
          <subagent id="library-researcher" type="general">
            <objective>
              Research latest stable versions and best practices for libraries/frameworks from architecture:
              - Latest API documentation and breaking changes
              - Security vulnerabilities or updates
              - Performance improvements or deprecations
              - Best practices for current versions
              Embed specific version numbers, API endpoints, and critical information.
            </objective>
            <context>
              <technologies>{identified_technologies}</technologies>
            </context>
            <output-var>{web_intelligence}</output-var>
          </subagent>
        </check>

        <sync-point>Wait for all agents to complete analysis</sync-point>
      </invoke-parallel>

      <output>‚úÖ All autonomous agents completed! Aggregating findings...</output>

      <!-- Aggregate all results into comprehensive context -->
      <action>Synthesize findings from all agents:
        - Epic Intelligence: {epic_intelligence}
        - Architecture Intelligence: {arch_intelligence}
        - Previous Story Intelligence: {previous_intelligence} (if available)
        - Git Patterns: {git_intelligence} (if available)
        - Library Research: {web_intelligence} (if available)
      </action>

      <output>üìä Comprehensive context gathered from parallel autonomous analysis</output>
    </check>

    <!-- Fallback: Manual sequential analysis if Task tool unavailable -->
    <else>
      <output>‚ÑπÔ∏è Task tool unavailable - using manual sequential analysis</output>

      <!-- Original manual analysis logic -->
      <action>From {epics_content}, extract Epic {{epic_num}} complete context:</action>
      **EPIC ANALYSIS:** - Epic objectives and business value - ALL stories in this epic for cross-story context - Our specific story's requirements, user story statement, acceptance criteria - Technical requirements and constraints - Dependencies on other stories/epics - Source hints pointing to original documents

      <action>Extract our story ({{epic_num}}-{{story_num}}) details:</action>
      **STORY FOUNDATION:** - User story statement (As a, I want, so that) - Detailed acceptance criteria (already BDD formatted) - Technical requirements specific to this story - Business context and value - Success criteria

      <check if="story_num > 1">
        <action>Load previous story file: {{story_dir}}/{{epic_num}}-{{previous_story_num}}-*.md</action>
        **PREVIOUS STORY INTELLIGENCE:** - Dev notes and learnings from previous story - Review feedback and corrections needed - Files that were created/modified and their patterns - Testing approaches that worked/didn't work - Problems encountered and solutions found - Code patterns established
        <action>Extract all learnings that could impact current story implementation</action>
      </check>

      <check if="git repository detected">
        <action>Get last 5 commit titles to understand recent work patterns</action>
        <action>Analyze 1-5 most recent commits for relevance to current story:
          - Files created/modified
          - Code patterns and conventions used
          - Library dependencies added/changed
          - Architecture decisions implemented
          - Testing approaches used
        </action>
        <action>Extract actionable insights for current story implementation</action>
      </check>
    </else>
  </step>

  <step n="3" goal="Create comprehensive self-sufficient story file">
    <critical>üìù CREATE ULTIMATE SELF-SUFFICIENT STORY FILE - 100% autonomous development ready!</critical>
    <critical>üéØ EMBED ALL CONTEXT - Zero external references, story file contains EVERYTHING!</critical>

    <action>Initialize from template.md: {default_output_file}</action>
    <template-output file="{default_output_file}">story_header</template-output>

    <!-- Story foundation from epic intelligence -->
    <template-output file="{default_output_file}">story_requirements</template-output>
    <action>Use {epic_intelligence} to populate:
      - User Story statement (As a, I want, so that)
      - Acceptance Criteria (BDD format from epic)
      - Business context and value
      - Success criteria
      - Dependencies on other stories
    </action>

    <!-- Developer context section - MOST IMPORTANT PART -->
    <critical>This section makes the story 100% self-sufficient - embed EVERYTHING from agents!</critical>
    <template-output file="{default_output_file}">developer_context_section</template-output>

    **EMBEDDED EPIC CONTEXT (from {epic_intelligence}):**
    <template-output file="{default_output_file}">epic_context_embedded</template-output>
    <action>Embed complete epic objectives, all related stories, dependencies - NO reference to epics.md</action>

    **EMBEDDED ARCHITECTURE REQUIREMENTS (from {arch_intelligence}):**
    <template-output file="{default_output_file}">architecture_embedded</template-output>
    <action>Embed:
      - Technical stack with versions
      - Code structure patterns and naming conventions
      - API patterns and data contracts
      - Database schemas and relationships
      - Security requirements and authentication patterns
      - Performance requirements and caching strategies
      - Testing standards and frameworks
      - Deployment patterns
      NO reference to architecture.md - everything embedded here!
    </action>

    **EMBEDDED LIBRARY/FRAMEWORK SPECIFICS (from {web_intelligence}):**
    <check if="{web_intelligence} available">
      <template-output file="{default_output_file}">library_framework_embedded</template-output>
      <action>Embed:
        - Specific library versions and why chosen
        - API endpoints with parameters and authentication
        - Security patches and considerations
        - Best practices for current versions
        - Migration notes if upgrading
      </action>
    </check>

    **EMBEDDED PREVIOUS LEARNINGS (from {previous_intelligence}):**
    <check if="{previous_intelligence} available">
      <template-output file="{default_output_file}">previous_learnings_embedded</template-output>
      <action>Embed:
        - Implementation decisions from previous story
        - Review feedback and corrections
        - Files created/modified and patterns used
        - Testing approaches that worked/failed
        - Problems encountered and solutions
        NO reference to previous story file - learnings embedded here!
      </action>
    </check>

    **EMBEDDED GIT PATTERNS (from {git_intelligence}):**
    <check if="{git_intelligence} available">
      <template-output file="{default_output_file}">git_patterns_embedded</template-output>
      <action>Embed:
        - Recent files modified and patterns
        - Code conventions established
        - Library dependencies added
        - Architecture decisions implemented
        - Testing approaches used
      </action>
    </check>

    **PROJECT CONTEXT (from {project_context}):**
    <check if="{project_context} available">
      <template-output file="{default_output_file}">project_context_embedded</template-output>
      <action>Embed relevant project-wide patterns and standards</action>
    </check>

    <!-- Final status update -->
    <template-output file="{default_output_file}">story_completion_status</template-output>

    <!-- Generate Ralph Tasks JSON manifest for fresh-context loop execution -->
    <critical>Each ralph task must be atomic enough for ONE fresh-context iteration with no prior context</critical>
    <action>Generate Ralph Tasks JSON from the same task breakdown.
      REFERENCE: {installed_path}/ralph-task-guide.md for decomposition best practices.

      REQUIRED JSON SCHEMA per task:
        - id: "task-N" (sequential)
        - title: imperative action description (matches task checkbox text)
        - acceptanceCriteria: ["AC1", "AC3"] (which story ACs this task addresses)
        - steps: specific actionable steps WITH file paths (subtasks become steps entries)
        - checkCommands: bash commands that verify completion (ls, grep, build checks)
        - passes: false (always false initially)

      TASK SIZING: each task must complete in ~3-5 min, touching 1-3 files.
      SEQUENCING: migrations ‚Üí scaffold ‚Üí implementation ‚Üí supporting features ‚Üí infrastructure ‚Üí tests.
      STEPS QUALITY: every step must name specific files, functions, or SQL. No vague "set up" or "configure properly".
      CHECK COMMANDS: at minimum include file existence (ls) + content check (grep) + build verification.
      Split any task larger than 3 files into multiple tasks.
      Order must match Tasks/Subtasks section exactly.
    </action>
    <template-output file="{default_output_file}">ralph_tasks_json</template-output>

    <!-- CRITICAL: Validate self-sufficiency -->
    <action>Validate story file self-sufficiency:
      ‚úÖ All epic context embedded (no epics.md reference needed)
      ‚úÖ All architecture requirements embedded (no architecture.md reference needed)
      ‚úÖ All library versions and APIs embedded (no web search needed)
      ‚úÖ All previous learnings embedded (no previous story reference needed)
      ‚úÖ All git patterns embedded (no git analysis needed)
      ‚úÖ Dev agent can implement using ONLY this story file + existing codebase
    </action>

    <!-- CRITICAL: Validate ralph-readiness -->
    <action>Validate ralph-readiness:
      ‚úÖ Section header is exactly "## Ralph Tasks JSON" (extract script requires this)
      ‚úÖ Each task has ALL required fields: id, title, acceptanceCriteria, steps, checkCommands, passes
      ‚úÖ NO obsolete fields (category, description, acceptance_criteria, verification)
      ‚úÖ Each ralph task is atomic (~3-5 min, 1-3 files, one fresh-context iteration)
      ‚úÖ steps array includes specific file paths and concrete details
      ‚úÖ checkCommands array has bash verification commands (ls, grep, build)
      ‚úÖ Tasks follow canonical sequence: migrations ‚Üí scaffold ‚Üí impl ‚Üí tests
      ‚úÖ All tasks have "passes": false
      ‚úÖ JSON tasks map 1:1 to markdown checkboxes
    </action>

    <!-- CRITICAL: Set status to ready-for-dev -->
    <action>Set story Status to: "ready-for-dev"</action>
    <action>Add completion note: "Autonomous parallel analysis completed - 100% self-sufficient story created with embedded context from {{number_of_agents}} agents"</action>

    <output>üéØ Self-sufficient story created! Dev agents need ONLY this file + codebase.</output>
  </step>

  <step n="4" goal="Update sprint status and finalize">
    <invoke-task>Validate against checklist at {installed_path}/checklist.md using _skad/core/tasks/validate-workflow.xml</invoke-task>
    <action>Save story document unconditionally</action>

    <!-- Update sprint status -->
    <check if="sprint status file exists">
      <action>Update {{sprint_status}}</action>
      <action>Load the FULL file and read all development_status entries</action>
      <action>Find development_status key matching {{story_key}}</action>
      <action>Verify current status is "backlog" (expected previous state)</action>
      <action>Update development_status[{{story_key}}] = "ready-for-dev"</action>
      <action>Save file, preserving ALL comments and structure including STATUS DEFINITIONS</action>
    </check>

    <action>Report completion</action>
    <output>**üéØ SELF-SUFFICIENT STORY CREATED WITH AUTONOMOUS PARALLEL ANALYSIS, {user_name}!**

      **Story Details:**
      - Story ID: {{story_id}}
      - Story Key: {{story_key}}
      - File: {{story_file}}
      - Status: ready-for-dev

      **Autonomous Analysis Summary:**
      - ‚úÖ Parallel agents spawned: {{agents_count}}
      - ‚úÖ Analysis time: ~90 seconds (3-4x faster than sequential)
      - ‚úÖ Self-sufficiency: 100% (zero external references)
      - ‚úÖ Context embedded: Epic, Architecture, Libraries, Previous learnings, Git patterns

      **Next Steps:**
      1. Review the self-sufficient story in {{story_file}}
      2. Run `dev-story` for AUTONOMOUS implementation (agents work in loops until complete!)
      3. Run `code-review` when complete (auto-marks done)
      4. Optional: If Test Architect module installed, run `/skad:tea:automate` to generate guardrail tests

      **Dev agents can now work autonomously using ONLY this story file + codebase!**
    </output>
  </step>

</workflow>
